% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils-webScraping.R
\name{find_remote_files_recursive}
\alias{find_remote_files_recursive}
\title{Recursively find file URLs from URL with an embedded HTML table (a remote directory)}
\usage{
find_remote_files_recursive(
  url,
  column = "Name",
  extensions = "[[:alnum:]]{2,5}"
)
}
\arguments{
\item{url}{\code{character(1)} A valid URL to scrape file data from. It is assumed
that the returned HTML has a table in it which indicates the remote
directory contents.}

\item{column}{\code{character(1)} Name of the column in the returned HTML table
to match files and directories from. The \code{url} is automatically prepended
to the values in the column, so they should be relative paths to other files
in the remote directory.}

\item{extensions}{\code{character()} vector with one of more file extensions to
to scrape from \code{url}. This should be the file extension only, with no dot.
It could also be a valid regex expression. Please note that all values will
be appended with "$" to match on the end of files and collapsed together
witht he "|" regex operator. The default matches any alphanumeric file
extensions between two and five character long.}
}
\value{
\code{character()} vector of remote file URLs to download from.
}
\description{
Recursively find file URLs from URL with an embedded HTML table (a remote directory)
}
